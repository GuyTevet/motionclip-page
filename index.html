<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="MotionCLIP: Exposing Human Motion Generation to CLIP Space"/>
  <meta property="og:url" content="https://motionclip.github.io/motionclip/"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <title>MotionCLIP: Exposing Human Motion Generation to CLIP Space</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/icon2.png">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MotionCLIP: Exposing Human Motion Generation to CLIP Space</h1>
        </div>
    </div>
  </div>   
</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.co.il/citations?hl=en&amp;user=P9ROgN8AAAAJ" target="_blank">Guy Tevet</a>*,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=VNDhTycAAAAJ&amp;hl=en" target="_blank">Brian Gordon</a>*,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=mnk__kYAAAAJ&amp;hl=en" target="_blank">Amir Hertz</a>,</span>
            
            <span class="author-block"><a href="https://www.cs.tau.ac.il/~amberman/" target="_blank">Amit H. Bermano</a>,</span>
            <span class="author-block"><a href="https://danielcohenor.com/" target="_blank">Daniel Cohen-Or</a></span>
            
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Tel Aviv University, Israel</span> 
            <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">* Equally contributed</span> 
            <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="_blank" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/source/MotionCLIP.pdf" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                            </span>
              <!-- </span> -->
              <!-- Colab Link. -->
              <span class="link-block">
                <a href="https://github.com/GuyTevet/MotionCLIP" target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>

              </span>
              <!-- </span> -->
              <!-- Colab Link. -->
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <!-- <div class="hero-body"> -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
      <div class="container">
      <div class="item">
      <div class="column is-centered has-text-centered">
        <img src="static/figures/teaser.png" alt="MotionCLIP"/>
      </div>

    </div>
  </div>
 <!--  </div> -->
  </div>
  </div>
 <!--  </div> -->
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="item">
          <p style="margin-bottom: 30px">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/MotionCLIP-projectpage-2.mp4"
          type="video/mp4">
        </video>
        </p>
        </div>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce MotionCLIP, a 3D human motion auto-encoder featuring a latent embedding that is disentangled, well behaved, and supports highly semantic textual descriptions.
MotionCLIP gains its unique power by aligning its latent space with that of the Contrastive Language-Image Pre-training (CLIP) model.  Aligning the human motion manifold to CLIP space implicitly infuses the extremely rich semantic knowledge of CLIP into the manifold. In particular, it helps continuity by placing semantically similar motions close to one another, and disentanglement, which is inherited from the CLIP-space structure.
MotionCLIP comprises a transformer-based motion auto-encoder, trained to reconstruct motion while being aligned to its text label's position in CLIP-space. 
We further leverage CLIP's unique visual understanding and inject an even stronger signal through aligning motion to rendered frames in a self-supervised manner.
We show that although CLIP has never seen the motion domain, MotionCLIP offers unprecedented text-to-motion abilities, allowing out-of-domain actions, disentangled editing, and abstract language specification. For example, the text prompt "couch" is decoded into a sitting down motion, due to lingual similarity, and the prompt "Spiderman" results in a web-swinging-like solution that is far from seen during training.  
In addition, we show how the introduced latent space can be leveraged for motion interpolation, editing and recognition.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/clouds_white_bg.png" alt="cars peace"/>
      </div>
     
    
  </div>
</div>
</div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">How does it work?</h2>
        <div class="content has-text-justified">
          <p>
MotionCLIP is a 3D motion auto-encoder that induces a latent embedding that is disentangled, well behaved, and supports highly semantic and elaborate descriptions. To this end, we employ <a href="https://openai.com/blog/clip/" target="_blank">CLIP</a>, a large scale visual-textual embedding model.
Our key insight is that even though CLIP has not been trained on the motion domain what-so-ever, we can inherit much of its latent space's 
virtue by enforcing its powerful and semantic structure onto the motion domain. To do this, we train a transformer-based auto-encoder that is aligned to the latent space of CLIP, using existing motion textual labels. 
</p>
<p>
In other words, we train an encoder to find the proper embedding of an input sequence in CLIP space, and a decoder that generates the most fitting motion to a given CLIP space latent code. 
To further improve the alignment with CLIP-space, we also leverage CLIP's visual encoder, and synthetically render frames to guide the alignment in a self-supervised manner . As we demonstrate, this step is crucial for out-of-domain generalization, since it allows finer-grained description of the motion, unattainable using text. 
		</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/blocks_white_bg.png" alt="cars peace"/>
      </div>
     
    
  </div>
</div>
</div>
</section>




<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Text-to-Motion</h2>
        <div class="content has-text-justified">
              <div class="column is-centered has-text-centered">
        <img src="static/figures/text-to-motion.gif" alt="cars peace"/>
      </div>
          <p>
Text-to-Motion is performed at inference time, using the CLIP text encoder and MotionCLIP decoder, without any further training.
Even though not directly trained for this task, MotionCLIP shows unprecedented performance in text-to-motion, dealing with explicit descriptions, subtle nuances and abstract language.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 




<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Olympic sports</h3>
        <img src="static/figures/sports1.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Style in free text</h3>
        <img src="static/figures/styles_free_text.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Cultural References</h3>
        <img src="static/figures/culture_1.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Cultural References</h3>
        <img src="static/figures/culture_2.gif" alt="cars peace"/>
      </div>
     
    
  </div>
</div>
</div>
</section>



<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Editing in Latent Space</h2>
        <div class="content has-text-justified">
              <div class="column is-centered has-text-centered">
        <img src="static/figures/edit.gif" alt="cars peace"/>
      </div>
          <p>
          To demonstrate how disentangled and uniform MotionCLIP latent space is, we experiment with latent-space arithmetic to edit motion. 
          These linear operations allow motion compositionality - the upper body action can be decomposed from the lower body one, and recomposed with another lower body performance. 
          Style can be added by simply adding the vector of the style name embedding. These two properties potentially enable intuitive and semantic editing even for novice users. 
</p>
<p>
In addition, linear interpolation between two latent codes yields semantic transitions between motions in both time and space. 
This is a strong indication to the smoothness of this representation. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Composition</h3>
        <img src="static/figures/latent_comp.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Latent style transfer</h3>
        <img src="static/figures/latent_style.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Interpolation</h3>
        <img src="static/figures/interp_shot.gif" alt="cars peace"/>
      </div>
      <div class="column is-centered has-text-centered">
      	<h3 class="title has-text-centered"> Interpolation</h3>
        <img src="static/figures/interp_dance.gif" alt="cars peace"/>
      </div>
     
    
  </div>
</div>
</div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Action Recognition</h2>
        <div class="content has-text-justified">
              <div class="column is-centered has-text-centered">
        <img src="static/figures/action_rec.gif" alt="cars peace"/>
      </div>
          <p>
Finally, we further demonstrate how well our latent spaces is semantically structured. 
We show how combined with the CLIP text encoder, MotionCLIP encoder can be used for action recognition. 
We follow BABEL 60-classes benchmark and train the model with <a href="https://babel.is.tue.mpg.de/" target="_blank">BABEL</a> class names instead of the raw text. 
At inference, we measure the cosine distance of a given motion sequence to all 60 class name encodings and apply softmax, as suggested originally for image classification. 
We compare Top-1 and Top-5 accuracy of MotionCLIP classifier to <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Two-Stream_Adaptive_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_CVPR_2019_paper.html" target="_blank">2s-AGCN</a>, as reported by BABEL. 
As can be seen, this is another example where our framework performs similarly to dedicated state-of-the-art methods, even though MotionCLIP was not designed for it.
          </p>
                        <div class="column is-centered has-text-centered">
        <img src="static/figures/ar_table.png" alt="cars peace"/>
      </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 




<footer class="footer">
 <!--  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
      href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
      <i class="fas fa-file-pdf"></i>
    </a>
    <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
      <i class="fab fa-github"></i>
    </a>
  </div> -->
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>


  <script type="text/javascript">
    var sc_project=12351448; 
    var sc_invisible=1; 
    var sc_security="c676de4f"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/12351448/0/c676de4f/1/"
    alt="Web Analytics"></a></div></noscript>
    <!-- End of Statcounter Code -->

  </body>
  </html>
